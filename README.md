
# ğŸ§  HysoLLM â€“ Makine Ã–ÄŸrenimi & LLM EÄŸitim AltyapÄ±sÄ±

HysoLLM, makine Ã¶ÄŸrenimi ve Ã¶zellikle bÃ¼yÃ¼k dil modeli (LLM) projelerinde **eÄŸitim sÃ¼reÃ§lerini dÃ¼zenlemek, deneyleri kaydetmek, yeniden Ã¼retilebilir hale getirmek ve modÃ¼ler bir mimari Ã¼zerine oturtmak** amacÄ±yla geliÅŸtirilmiÅŸ hafif bir frameworkâ€™tÃ¼r.

Bu altyapÄ±, modern ML projelerinde ihtiyaÃ§ duyulan temel bileÅŸenleri tek Ã§atÄ± altÄ±nda toplar:

- âš™ï¸ ModÃ¼ler model mimarileri  
- ğŸ”¤ Tokenizer sistemi (BPE + Simple)  
- ğŸ“¦ Deney yÃ¶netimi (run paths, manifest, logger, checkpoints, seed)  
- âš¡ EÄŸitim dÃ¶ngÃ¼sÃ¼ (trainer, callback sistemi)  
- ğŸ§¾ Config yÃ¶netimi (YAML/JSON + CLI override)  
- ğŸ“ Harici config dosyalarÄ± (configs/)  

---
## **ğŸš€ KullanÄ±m Ã–rneÄŸi**

- AÅŸaÄŸÄ±da HysoLLM bileÅŸenlerinin birlikte nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶steren gerÃ§ek bir Ã¶rnek bulunmaktadÄ±r.
AmaÃ§:  
**Model kodunu eÄŸitim mekanizmalarÄ±ndan tamamen ayÄ±rarak**, farklÄ± projelerde yeniden kullanÄ±labilir, dÃ¼zenli ve sÃ¼rdÃ¼rÃ¼lebilir bir yapÄ± oluÅŸturmak.
```python
from hyso.core.config import load_config_with_overrides
from hyso.core.storage import (
    RunPathFactory,
    get_logger,
    Manifest,
    save_manifest,
    CheckpointConfig,
    CheckpointManager,
    set_global_seed,
)
from hyso.core.tokenizer import HysoBPETokenizer
from hyso.core.models.encoder_only import HysoEncoderOnly
from hyso.core.train import Trainer

import torch
from torch.utils.data import DataLoader, TensorDataset


# ---------------------------------------------------------
# 1) Config yÃ¼kleme (+ override desteÄŸi)
# ---------------------------------------------------------

cfg = load_config_with_overrides(
    path="configs/base.yaml",
    override_pairs=["training.lr=0.0001", "model.dim=512"]
)


# ---------------------------------------------------------
# 2) Run path oluÅŸturma
# ---------------------------------------------------------

factory = RunPathFactory.from_root("runs")
run_paths = factory.create()

logger = get_logger("train", log_dir=run_paths.logs_dir)
logger.info(f"Run baÅŸlatÄ±ldÄ±: {run_paths.run_id}")


# ---------------------------------------------------------
# 3) Seed ayarÄ± (deterministik eÄŸitim iÃ§in)
# ---------------------------------------------------------

set_global_seed(cfg.training.seed)


# ---------------------------------------------------------
# 4) Manifest oluÅŸturma
# ---------------------------------------------------------

manifest = Manifest.new(
    run_id=run_paths.run_id,
    model=cfg.model,
    training=cfg.training,
    data={"name": "dummy"},
)

save_manifest(run_paths.manifest_path, manifest)
logger.info("Manifest kaydedildi.")


# ---------------------------------------------------------
# 5) Tokenizer yÃ¼kleme
# ---------------------------------------------------------

tokenizer = HysoBPETokenizer(
    lowercase=True,
    normalize="NFKC",
    cache_size=5000,
)


# ---------------------------------------------------------
# 6) Model oluÅŸturma
# ---------------------------------------------------------

model = HysoEncoderOnly(
    dim=cfg.model.dim,
    num_layers=cfg.model.layers,
    vocab_size=tokenizer.vocab_size,
)

model = model.to(cfg.training.device)


# ---------------------------------------------------------
# 7) Dataset & Dataloader
# ---------------------------------------------------------

X = torch.randint(0, tokenizer.vocab_size, (100, 32))
y = torch.randint(0, tokenizer.vocab_size, (100, 32))

dataset = TensorDataset(X, y)
loader = DataLoader(dataset, batch_size=cfg.training.batch_size, shuffle=True)


# ---------------------------------------------------------
# 8) Optimizer & Scheduler
# ---------------------------------------------------------

optimizer = torch.optim.Adam(model.parameters(), lr=cfg.training.lr)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)


# ---------------------------------------------------------
# 9) Checkpoint yÃ¶neticisi
# ---------------------------------------------------------

ckpt_cfg = CheckpointConfig.from_dir(
    directory=run_paths.checkpoints_dir,
    best_metric_name="val_loss",
    best_mode="min",
)

checkpoint_manager = CheckpointManager(ckpt_cfg)


# ---------------------------------------------------------
# 10) Trainer oluÅŸturma
# ---------------------------------------------------------

trainer = Trainer(
    model=model,
    optimizer=optimizer,
    scheduler=scheduler,
    tokenizer=tokenizer,
    config=cfg,
    run_paths=run_paths,
    checkpoint_manager=checkpoint_manager,
    logger=logger,
)


# ---------------------------------------------------------
# 11) EÄŸitim dÃ¶ngÃ¼sÃ¼
# ---------------------------------------------------------

trainer.fit(
    train_loader=loader,
    val_loader=loader,
    epochs=cfg.training.epochs,
)

logger.info("EÄŸitim tamamlandÄ±.")

```
---

# ğŸ“ Proje YapÄ±sÄ±
Her klasÃ¶r aÅŸaÄŸÄ±da aÃ§Ä±klanmaktadÄ±r.
```bash
core/
  models/
  tokenizer/
  storage/
  train/
  config/
  configs/
```

---

# ğŸ”¤ 1. Tokenizer ModÃ¼lÃ¼ (`hyso/core/tokenizer/`)

Tokenizer yapÄ±sÄ± metni modele uygun ID dizilerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. HysoLLM iki tokenizer iÃ§erir:

---

### **â€¢ HysoBPETokenizer (BPE)**  
Byte Pair Encoding tabanlÄ± tokenizer.

**YÃ¶ntemler & yetenekler:**
- BPE merge kurallarÄ±na dayalÄ± alt birim Ã¼retimi  
- Ã–zel token ID yÃ¶netimi  
- Batch encode/decode  
- Seq2Seq encoder ve decoder iÃ§in ayrÄ± encode fonksiyonlarÄ±  
- UTF-8 byte-level iÅŸleme desteÄŸi  

**KullanÄ±lan Teknolojiler:**
- Python  
- PyTorch (tensor dÃ¶nÃ¼ÅŸÃ¼mleri)  
- Unicode processing  
- BPE algoritmasÄ±  

---

### **â€¢ HysoSimpleTokenizer (Word-level)**  
Kelime temelli sade tokenizer.

**YÃ¶ntemler:**
- Temel whitespace tokenizasyonu  
- Kelime frekansÄ±na gÃ¶re vocabulary oluÅŸturma  
- Batch encode/decode  
- Mask Ã¼retimi  

**KullanÄ±lan Teknolojiler:**
- Python  
- PyTorch  
- Temel NLP tokenizasyon teknikleri  

---

# ğŸ§© 2. Model ModÃ¼lÃ¼ (`hyso/core/models/`)

Bu klasÃ¶r HysoLLM model mimarilerini iÃ§erir. TÃ¼m modeller modÃ¼ler ve geniÅŸletilebilir yapÄ±dadÄ±r.

---

### **Model mimarileri:**
- **Encoder-Decoder Transformer**  
- **Encoder-only LLM** (BERT/LLM tarzÄ±)  
- **Decoder-only Model** (GPT tarzÄ±)

---

### **Her modelin sunduÄŸu yÃ¶ntemler:**
- `forward()`  
- `generate()` (decoder-only)  
- `encode()` / `decode()` (enc-dec yapÄ±larÄ±)  
- RoPE pozisyonel embedding  
- Attention katmanlarÄ±  
- DropPath, LayerNorm, RMSNorm gibi modern bileÅŸenler  

**KullanÄ±lan Teknolojiler:**
- PyTorch (nn.Module)  
- Multi-Head Attention  
- Rotary Positional Embedding (RoPE)  
- SwiGLU / GeLU aktivasyonlarÄ±  
- Residual / PreNorm mimarileri  

---

# ğŸ“¦ 3. Storage ModÃ¼lÃ¼ (`hyso/core/storage/`)

Bu modÃ¼l HysoLLMâ€™in gerÃ§ek â€œdeney yÃ¶netimiâ€ Ã§ekirdeÄŸidir.
KlasÃ¶r yapÄ±sÄ±nÄ± otomatik oluÅŸturur.

**YÃ¶ntemler:**  
- `create()`  
- `run_id` Ã¼retimi  
- klasÃ¶r kurulumu  

## **â€¢ Logger**  
Hem konsola hem dosyaya temiz log yazan yapÄ±landÄ±rÄ±labilir logger.

**YÃ¶ntemler:**  
- `get_logger(name, log_dir)`  
- Formatlama (timestamp, level, name, message)  
- Rotating log desteÄŸi  


## **â€¢ Manifest**  
Her eÄŸitimin kimlik kartÄ±dÄ±r.

Ä°Ã§erik:  
- model bilgisi  
- eÄŸitim bilgisi  
- veri seti bilgisi  
- ortam (Python, OS, CUDA)  
- hyperparametreler  
- timestamp  

**YÃ¶ntemler:**  
- `Manifest.new()`  
- `save_manifest()`  
- `load_manifest()`  

## **â€¢ CheckpointManager**  
EÄŸitim sÄ±rasÄ±nda modelleri gÃ¼venli ÅŸekilde kaydeder.

**YÃ¶ntemler:**
- `save(epoch, model, optimizer, scheduler)`  
- `load_latest()`  
- `load_best()`  
- `restore_objects()`  
- max_to_keep ile eski checkpoint silme  


## **â€¢ Seed YÃ¶netimi**
TÃ¼m ortamÄ± deterministik hale getirir.

**YÃ¶ntemler:**  
- `set_global_seed(seed)`  

**KullanÄ±lan Teknolojiler (tÃ¼m storage):**
- PyTorch  
- Python logging  
- JSON  
- UUID  
- Pathlib  
- Datetime  

---

# âš¡ 4. Train ModÃ¼lÃ¼ (`hyso/core/train/`)

Bu modÃ¼l model eÄŸitimi iÃ§in gerekli tÃ¼m yapÄ±lara sahiptir.

### **Ä°Ã§erik:**

### **â€¢ Trainer**
Model, veri, optimizer, scheduler, storage ve config bileÅŸenlerini bir araya getiren ana eÄŸitim sÄ±nÄ±fÄ±.

**YÃ¶ntemler:**
- `train_epoch()`  
- `validate()`  
- `fit()`  
- Loss hesaplama  
- Metrics kaydetme  


### **â€¢ Callback Sistemi**
EÄŸitimin belirli aÅŸamalarÄ±nda Ã§alÄ±ÅŸacak kÃ¼Ã§Ã¼k kancalar.

**YÃ¶ntemler:**
- `on_train_start()`  
- `on_epoch_end()`  
- `on_step_end()`  
- CallbackList ile Ã§oklu callback desteÄŸi  

### **â€¢ Metrics Logging**
EÄŸitim ve validasyon metriklerini CSVâ€™e yazar.

**KullanÄ±lan Teknolojiler:**
- PyTorch (dataset, dataloader, optim, scheduler)  
- Callback pattern  
- CSV logging  
- Checkpoint entegrasyonu  

# ğŸ§¾ 5. Config ModÃ¼lÃ¼ (`hyso/core/config/`)

Config sistemi ayarlarÄ± koddan ayÄ±rÄ±r ve tÃ¼m eÄŸitim sÃ¼reÃ§lerini yapÄ±landÄ±rÄ±labilir hale getirir.


### **YapÄ±lan iÅŸlemler:**
- YAML / JSON config dosyasÄ± yÃ¼kleme  
- CLI override desteÄŸi  
  (`training.lr=0.0001 model.layers=12` gibi)  
- Deep merge  
- Config kaydetme / okuma  
- Attribute-style eriÅŸim:  
  `cfg.training.lr`  


### **YÃ¶ntemler:**
- `load_config(path)`  
- `parse_overrides(argv)`  
- `merge_config(base, override)`  
- `load_config_with_overrides()`  
- `save_config()`  

**KullanÄ±lan Teknolojiler:**
- PyYAML  
- JSON  
- Python AST parsing  
- Recursive merge algoritmasÄ±  

---

# ğŸ“ 6. Configs KlasÃ¶rÃ¼ (`configs/`)

Bu klasÃ¶r train modÃ¼lÃ¼ iÃ§in harici ayar dosyalarÄ±nÄ± iÃ§erir.

Ã–rnek dosyalar:
- `base.yaml`
- `encoder_small.yaml`
- `encoder_large.yaml`
- `lr_sweep.yaml`

Bu sayede:

- Deney ayarlarÄ± versiyonlanabilir,  
- FarklÄ± modeller iÃ§in hÄ±zlÄ± switching yapÄ±labilir,  
- Manifest + config birleÅŸince tam reproducibility saÄŸlanÄ±r.

**KullanÄ±lan Teknolojiler:**  
- YAML  
- JSON  

---

# ğŸ§© Ã–zet

HysoLLM yalnÄ±zca model mimarisi deÄŸil;  
**tam bir eÄŸitim altyapÄ±sÄ±, deney yÃ¶netim sistemi, config framework ve modÃ¼ler ML yapÄ± setidir.**

Bu repo:

- ğŸ”¤ Tokenizer sistemini  
- âš™ï¸ Model mimarisini  
- ğŸ“¦ Storage ve deney yÃ¶netimini  
- âš¡ EÄŸitim altyapÄ±sÄ±nÄ±  
- ğŸ§¾ Config yÃ¶netimini  

birbirinden ayrÄ±lmÄ±ÅŸ, temiz ve profesyonel ÅŸekilde organize eder.

--- 

# âœ¨ Lisans
MIT License



